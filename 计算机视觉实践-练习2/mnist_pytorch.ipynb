{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa2dec-d410-4ede-a80c-348a38fe9785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)  #创建一个输入通道为1，输出feature map数量为6,卷积核大小5*5\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)   #池化窗口为2，步长为2\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)  #全连接层 输出特征维度120\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "   \n",
    "\n",
    "#定义训练过程  \n",
    "def train_LeNet(model, device, trainloader, optimizer, epoch):\n",
    "    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True\n",
    "    model.train()\n",
    "    total = 0\n",
    "    correct =0.0\n",
    "    \n",
    "    #enumerate迭代已加载的数据集,同时获取数据和数据下标\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        #把模型部署到device上\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #初始化梯度\n",
    "        optimizer.zero_grad()\n",
    "        #保存训练结果\n",
    "        outputs = model(inputs)\n",
    "        #计算损失和\n",
    "        #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        #获取最大概率的预测结果\n",
    "        #dim=1表示返回每一行的最大值对应的列下标\n",
    "        predict = outputs.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predict == labels).sum().item()\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #更新参数\n",
    "        optimizer.step()\n",
    "        if i % 1000 == 0:\n",
    "            #loss.item()表示当前loss的数值\n",
    "            print(\"Train Epoch{} \\t Loss: {:.6f}, accuracy: {:.6f}%\".format(epoch, loss.item(), 100*(correct/total)))\n",
    "            Loss.append(loss.item())\n",
    "            Accuracy.append(correct/total)\n",
    "    return loss.item(), correct/total\n",
    "\n",
    "\n",
    "#定义测试过程\n",
    "def test_LeNet(model, device, testloader):\n",
    "    #模型验证, 必须要写, 否则只要有输入数据, 即使不训练, 它也会改变权值\n",
    "    #因为调用eval()将不启用 BatchNormalization 和 Dropout, BatchNormalization和Dropout置为False\n",
    "    model.eval()\n",
    "    #统计模型正确率, 设置初始值\n",
    "    correct = 0.0\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    #torch.no_grad将不会计算梯度, 也不会进行反向传播\n",
    "    with torch.no_grad():\n",
    "        for data, label in testloader:\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, label).item()\n",
    "            predict = output.argmax(dim=1)\n",
    "            #计算正确数量\n",
    "            total += label.size(0)\n",
    "            correct += (predict == label).sum().item()\n",
    "        #计算损失值\n",
    "        print(\"test_avarage_loss: {:.6f}, accuracy: {:.6f}%\".format(test_loss/total, 100*(correct/total)))\n",
    "\n",
    "\n",
    "#利用训练好的模型进行数字识别\n",
    "def test_model(path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = torch.load(path + '/models/mnist.pth') #加载模型\n",
    "    model = model.to(device)\n",
    "    model.eval()    #把模型转为test模式\n",
    "    \n",
    "    #读取要预测的图片\n",
    "    img = cv2.imread(path + \"/img/9_x.jpg\")\n",
    "    img=cv2.resize(img,dsize=(32,32),interpolation=cv2.INTER_NEAREST)\n",
    "    plt.imshow(img,cmap=\"gray\") # 显示图片\n",
    "    plt.axis('off') # 不显示坐标轴\n",
    "    plt.title('Q_number')\n",
    "    plt.show()\n",
    "    \n",
    "    # 导入图片，图片扩展后为[1，1，32，32]\n",
    "    trans = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#图片转为灰度图，因为mnist数据集都是灰度图\n",
    "    img = trans(img)\n",
    "    img = img.to(device)\n",
    "    img = img.unsqueeze(0)  #图片扩展多一维,因为输入到保存的模型中是4维的[batch_size,通道,长，宽]，而普通图片只有三维，[通道,长，宽]\n",
    "    print(img.shape)\n",
    "    \n",
    "    #预测 \n",
    "    output = model(img)\n",
    "    print(output)\n",
    "    prob = F.softmax(output,dim=1) #prob是10个分类的概率\n",
    "    print(\"概率：\",prob)\n",
    "    value, predicted = torch.max(output.data, 1)\n",
    "    predict = output.argmax(dim=1)\n",
    "    print(\"预测类别：\",predict.item())\n",
    "\n",
    "    \n",
    "if __name__ ==\"__main__\":   \n",
    "    '''\n",
    "    1、定义数据预处理方式\n",
    "    '''\n",
    "    pipline_train = transforms.Compose([    #训练集\n",
    "        #随机旋转图片\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #将图片尺寸resize到32x32\n",
    "        transforms.Resize((32,32)),\n",
    "        #将图片转化为Tensor格式\n",
    "        transforms.ToTensor(),\n",
    "        #正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)\n",
    "        transforms.Normalize((0.1307,),(0.3081,))    \n",
    "    ])    \n",
    "    pipline_test = transforms.Compose([     #测试集\n",
    "        #将图片尺寸resize到32x32\n",
    "        transforms.Resize((32,32)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,),(0.3081,))\n",
    "    ])\n",
    "    \n",
    "    '''\n",
    "    2、数据集获取并加载\n",
    "    '''   \n",
    "    #下载数据集 \n",
    "    path = os.path.dirname(os.path.abspath(__file__)) \n",
    "    print(path)\n",
    "    train_set = datasets.MNIST(root= path+\"/dataset\", train=True, download=True, transform=pipline_train)\n",
    "    test_set = datasets.MNIST(root= path+\"/dataset\", train=False, download=True, transform=pipline_test)\n",
    "    #加载数据集\n",
    "    trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    testloader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)    \n",
    "     \n",
    "    '''\n",
    "    3、定义模型与优化器\n",
    "    '''\n",
    "    #创建模型，部署gpu\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LeNet().to(device)\n",
    "    #定义优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    '''\n",
    "    4、模型训练并计算loss和accuracy\n",
    "    '''\n",
    "    #调用\n",
    "    epoch = 50\n",
    "    Loss = []\n",
    "    Accuracy = []\n",
    "    for epoch in range(1, epoch+1):\n",
    "        print(\"start_time\",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "        loss, acc = train_LeNet(model, device, trainloader, optimizer, epoch)\n",
    "        Loss.append(loss)\n",
    "        Accuracy.append(acc)\n",
    "        test_LeNet(model, device, testloader)\n",
    "        print(\"end_time: \",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'\\n')\n",
    "\n",
    "    print('Finished Training')\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(Loss)\n",
    "    plt.title('Q_Loss')\n",
    "    # plt.show()\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(Accuracy)\n",
    "    plt.title('Q_Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    '''\n",
    "    5、模型保存\n",
    "    '''\n",
    "    print(model)\n",
    "    path = os.path.dirname(os.path.abspath(__file__))\n",
    "    weight_path = path + '/models/mnist.pth'\n",
    "    print(weight_path)\n",
    "    torch.save(model, weight_path) #保存模型   \n",
    "    \n",
    "    '''\n",
    "    6、模型测试\n",
    "    '''\n",
    "    path = os.path.dirname(os.path.abspath(__file__))\n",
    "    test_model(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
